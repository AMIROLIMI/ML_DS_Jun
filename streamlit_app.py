import streamlit as st
import pandas as pd
import numpy as np
from sklearn.impute import SimpleImputer
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import roc_curve, auc, roc_auc_score
from mlxtend.plotting import plot_decision_regions
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import io

def evaluate_model(model, X_test, y_test, model_name):
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
    plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.title(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: {model_name}")
    st.pyplot(fig)

    st.subheader(f"–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.write(pd.DataFrame(report).transpose())

def analyze_classification_results(knc, log_reg, dtc, X_test, y_test):
    evaluate_model(knc, X_test, y_test, "K-Nearest Neighbors")
    evaluate_model(log_reg, X_test, y_test, "Logistic Regression")
    evaluate_model(dtc, X_test, y_test, "Decision Tree")


def load_data(url):
    data = pd.read_csv(url, header=None)
    data.columns = [f"A{i}" for i in range(1, 17)]
    return data

def preprocess_features(data):
    data = data.drop(columns=["A1", "A4", "A5", "A6", "A7", "A9", "A10", "A12", "A13"])
    data["A16"] = data["A16"].apply(lambda x: 1 if x == "+" else 0)
    data.replace("?", np.nan, inplace=True)
    for col in data.columns:
        data[col] = pd.to_numeric(data[col], errors="coerce")
    for col in data.columns:
        if col != "A16":  
            data[col] = data.groupby("A16")[col].transform(lambda x: x.fillna(x.mean()))
    for col in ["A11", "A14", "A15", "A16"]:
        data[col] = data[col].astype(int)

    return data

    
def feature_selection(data):
    correlation_with_target = data.drop(columns=["A16"]).corrwith(data["A16"]).sort_values(ascending=False)
    st.subheader("üîπ –ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ —Å —Ç–∞—Ä–≥–µ—Ç–æ–º (A16)")
    st.write(correlation_with_target)
    unique_values_count = data.nunique()
    st.subheader("üîπ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –≤ –∫–∞–∂–¥–æ–º –ø—Ä–∏–∑–Ω–∞–∫–µ")
    st.write(unique_values_count)
    significant_features = unique_values_count[unique_values_count > 10].index.tolist()
    significant_features_with_correlation = correlation_with_target[significant_features].sort_values(ascending=False)
    st.subheader("üîπ –¢—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Å –±–æ–ª–µ–µ —á–µ–º 10 —É–Ω–∏–∫–∞–ª—å–Ω—ã–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏")
    st.write(significant_features_with_correlation.head(3))
    return significant_features_with_correlation.head(3).index.tolist()

def plot_3d_graph(data):
    st.subheader("–í—ã–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è 3D-–≥—Ä–∞—Ñ–∏–∫–∞")
    
    available_features = list(data.columns)
    available_features.remove("A16") 
    feature_x = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –ø–µ—Ä–≤—ã–π –ø—Ä–∏–∑–Ω–∞–∫ (X-–æ—Å—å):", available_features, index=available_features.index("A11"))
    feature_y = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –≤—Ç–æ—Ä–æ–π –ø—Ä–∏–∑–Ω–∞–∫ (Y-–æ—Å—å):", available_features, index=available_features.index("A8"))
    feature_z = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ —Ç—Ä–µ—Ç–∏–π –ø—Ä–∏–∑–Ω–∞–∫ (Z-–æ—Å—å):", available_features, index=available_features.index("A3"))
    fig = plt.figure(figsize=(10, 8))
    ax = fig.add_subplot(111, projection='3d')
    scatter = ax.scatter(data[feature_x], data[feature_y], data[feature_z], c=data['A16'], marker='o', cmap='viridis')
    ax.set_xlabel(feature_x)
    ax.set_ylabel(feature_y)
    ax.set_zlabel(feature_z)
    ax.set_title(f'3D-–≥—Ä–∞—Ñ–∏–∫ –¥–∞–Ω–Ω—ã—Ö: {feature_x}, {feature_y}, {feature_z}')
    
    fig.colorbar(scatter, ax=ax, label='–ö–ª–∞—Å—Å (A16)')
    st.pyplot(fig)

    
def classification_models(data):
    X = data.drop(columns=["A16"])
    y = data["A16"]
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=11)
    scaler_option = st.selectbox("–í—ã–±–µ—Ä–∏—Ç–µ –º–µ—Ç–æ–¥ –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏:", ["StandardScaler", "MinMaxScaler"])
    scaler = StandardScaler() if scaler_option == "StandardScaler" else MinMaxScaler()
    
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    st.write("–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—Ç–æ—è—Ç —Ç–µ –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–∏—Ç—Ä—ã –∫–æ—Ç–æ—Ä—ã–µ –≤—ã —É–∫–∞–∑–∞–ª–∏ –≤ –∏–Ω–¥–∏–≤–∏–∞–ª—å–Ω—ã—Ö –∑–∞–¥–∞—á")
    kn_neighbors = st.slider("–ß–∏—Å–ª–æ —Å–æ—Å–µ–¥–µ–π (k) –¥–ª—è KNN:", min_value=1, max_value=15, value=3)
    log_max_iter = st.slider("–ú–∞–∫—Å. –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –ª–æ–≥–∏—Å—Ç–∏—á–µ—Å–∫–æ–π —Ä–µ–≥—Ä–µ—Å—Å–∏–∏:", min_value=100, max_value=1000, value=565, step=50)
    dt_max_depth = st.slider("–ú–∞–∫—Å. –≥–ª—É–±–∏–Ω–∞ –¥–µ—Ä–µ–≤–∞ —Ä–µ—à–µ–Ω–∏–π:", min_value=1, max_value=20, value=5)

    knc = KNeighborsClassifier(n_neighbors=kn_neighbors)
    log_reg = LogisticRegression(max_iter=log_max_iter)
    dtc = DecisionTreeClassifier(max_depth=dt_max_depth)

    X_train = np.array(X_train)[:, :2]
    X_test = np.array(X_test)[:, :2]
    y_train = np.array(y_train)

    knc.fit(X_train, y_train)
    log_reg.fit(X_train, y_train)
    dtc.fit(X_train, y_train)

    st.subheader("üîπ –ú–æ–¥–µ–ª–∏ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ –æ–±—É—á–µ–Ω—ã")
    st.write(f"–í—ã–±—Ä–∞–Ω–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: {scaler_option}")
    st.write(f"KNN (k={kn_neighbors}), Logistic Regression (max_iter={log_max_iter}), Decision Tree (max_depth={dt_max_depth}) —É—Å–ø–µ—à–Ω–æ –æ–±—É—á–µ–Ω—ã.")

    return knc, log_reg, dtc, X_train, X_test, y_train, y_test


def plot_decision_boundaries(X_train, y_train, knc, log_reg, dtc):
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    classifiers = [(knc, "K-Nearest Neighbors"), (log_reg, "Logistic Regression"), (dtc, "Decision Tree")]
    for idx, (clf, title) in enumerate(classifiers):
        plt.sca(axes[idx])  
        plot_decision_regions(X_train, y_train, clf=clf, legend=2)
        plt.xlabel("A2")
        plt.ylabel("A3")
        plt.title(title)
    plt.suptitle("–≥—Ä–∞–Ω–∏—Ü–∞ —Ä–µ—à–µ–Ω–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ ", fontsize=14)
    plt.tight_layout(rect=[0, 0, 1, 0.95])
    st.pyplot(plt)


def plot_roc_curves(knc, log_reg, dtc, X_test, y_test):
    plt.clf()
    y_score_knc = knc.predict_proba(X_test)[:, 1]
    y_score_log_reg = log_reg.predict_proba(X_test)[:, 1]
    y_score_dtc = dtc.predict_proba(X_test)[:, 1]
    fpr_knc, tpr_knc, _ = roc_curve(y_test, y_score_knc)
    fpr_log_reg, tpr_log_reg, _ = roc_curve(y_test, y_score_log_reg)
    fpr_dtc, tpr_dtc, _ = roc_curve(y_test, y_score_dtc)
    auc_knc = auc(fpr_knc, tpr_knc)
    auc_log_reg = auc(fpr_log_reg, tpr_log_reg)
    auc_dtc = auc(fpr_dtc, tpr_dtc)
    plt.figure(figsize=(10, 8))
    plt.plot(fpr_knc, tpr_knc, label=f'KNN (AUC = {auc_knc:.2f})', linestyle='-', color='blue')
    plt.plot(fpr_log_reg, tpr_log_reg, label=f'Logistic Regression (AUC = {auc_log_reg:.2f})', linestyle='-', color='orange')
    plt.plot(fpr_dtc, tpr_dtc, label=f'Decision Tree (AUC = {auc_dtc:.2f})', linestyle='-', color='green')
    plt.plot([0, 1], [0, 1], linestyle='--', color='gray')
    plt.xlabel('FPR')
    plt.ylabel('TPR')
    plt.title('ROC-–∫—Ä–∏–≤—ã–µ')
    plt.legend()
    plt.grid()
    st.pyplot(plt)

def evaluate_models(knc, log_reg, dtc, X_train, X_test, y_train, y_test):
    auc_train_knc = roc_auc_score(y_train, knc.predict_proba(X_train)[:, 1])
    auc_test_knc = roc_auc_score(y_test, knc.predict_proba(X_test)[:, 1])
    auc_train_log_reg = roc_auc_score(y_train, log_reg.predict_proba(X_train)[:, 1])
    auc_test_log_reg = roc_auc_score(y_test, log_reg.predict_proba(X_test)[:, 1])
    auc_train_dtc = roc_auc_score(y_train, dtc.predict_proba(X_train)[:, 1])
    auc_test_dtc = roc_auc_score(y_test, dtc.predict_proba(X_test)[:, 1])
    results = {"–ú–æ–¥–µ–ª—å": ["KNN", "Logistic Regression", "Decision Tree"],
                "AUC (Train)": [auc_train_knc, auc_train_log_reg, auc_train_dtc],
                "AUC (Test)": [auc_test_knc, auc_test_log_reg, auc_test_dtc]}

    st.write("**–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π –ø–æ AUC**")
    st.dataframe(results)
    
def evaluate_model(model, X_test, y_test, model_name):
    # –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏
    y_pred = model.predict(X_test)
    cm = confusion_matrix(y_test, y_pred)
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Class 0", "Class 1"], yticklabels=["Class 0", "Class 1"])
    plt.xlabel("–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.ylabel("–ò—Å—Ç–∏–Ω–Ω—ã–π –∫–ª–∞—Å—Å")
    plt.title(f"–ú–∞—Ç—Ä–∏—Ü–∞ –æ—à–∏–±–æ–∫: {model_name}")
    st.pyplot(fig)
    st.subheader(f"–ú–µ—Ç—Ä–∏–∫–∏ –º–æ–¥–µ–ª–∏ {model_name}")
    report = classification_report(y_test, y_pred, output_dict=True)
    st.write(pd.DataFrame(report).transpose())
def analyze_classification_results(knc, log_reg, dtc, X_test, y_test):
    evaluate_model(knc, X_test, y_test, "K-Nearest Neighbors")
    evaluate_model(log_reg, X_test, y_test, "Logistic Regression")
    evaluate_model(dtc, X_test, y_test, "Decision Tree")

def visualize_feature_distributions(data):
    fig, axes = plt.subplots(1, 3, figsize=(18, 5))
    features = ["A11", "A8", "A3"]
    for i, feature in enumerate(features):
        sns.histplot(data, x=feature, hue="A16", element="step", bins=20, ax=axes[i], palette="viridis")
        axes[i].set_title(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ {feature} –ø–æ –∫–ª–∞—Å—Å–∞–º")
    plt.tight_layout()
    st.pyplot(fig)

def visualize_pairplot(data):
    selected_features = ["A11", "A8", "A3", "A16"]
    pairplot_fig = sns.pairplot(data[selected_features], hue="A16", palette="viridis")
    st.pyplot(pairplot_fig)

def visualize_correlation_matrix(data):
    corr_matrix = data.corr()
    fig, ax = plt.subplots(figsize=(10, 8))
    sns.heatmap(corr_matrix, annot=True, fmt=".2f", cmap="coolwarm", ax=ax)
    plt.title("–ú–∞—Ç—Ä–∏—Ü–∞ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
    st.pyplot(fig)

def visualize_data(data):
    visualize_feature_distributions(data)
    visualize_pairplot(data)
    visualize_correlation_matrix(data)



def main():
    st.title("üìä –ê–Ω–∞–ª–∏–∑ –Ω–∞–±–æ—Ä–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è UCI")
    st.subheader("üîπ –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö")
    url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö:", 
                       "https://raw.githubusercontent.com/AMIROLIMI/ML_DS_Jun/master/HW4-crx.data")
    if url:
        data = load_data(url)

        num_rows = st.slider("–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è:", 
                             min_value=4, max_value=len(data), value=5)
        
        st.subheader("–ü—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Å–º–æ—Ç—Ä –¥–∞–Ω–Ω—ã—Ö")
        st.dataframe(data.head(num_rows))

        st.subheader("üîπ –®–∞–≥ 2: –û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–æ–∫ –∫–ª–∞—Å—Å–æ–≤")
        st.subheader("üìâ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        st.write(data.isna().sum())

        buffer = io.StringIO()
        data.info(buf=buffer)
        info_str = buffer.getvalue()

        st.subheader("üî¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        st.text(info_str)
        st.subheader("–£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Å—Ç–æ–ª–±—Ü–µ A16 –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        st.write(data["A16"].unique())
        st.markdown(""" 
        –í —ç—Ç–∏—Ö –¥–∞–Ω–Ω—ã—Ö –Ω–µ—Ç –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π, –Ω–æ –µ—Å—Ç—å –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –∫–∞–∫ "?". 
        –≠—Ç–∏ –∑–Ω–∞—á–µ–Ω–∏—è –±—É–¥—É—Ç —É–¥–∞–ª–µ–Ω—ã –∏ –∑–∞–º–µ–Ω–µ–Ω—ã —Å—Ä–µ–¥–Ω–∏–º–∏ –∑–Ω–∞—á–µ–Ω–∏—è–º–∏. –ê –∫–ª–∞—Å—Å–æ–≤ 2, –ø–æ —ç—Ç–æ–º—É –º–æ–∂–Ω–æ –Ω–∏—á–µ–≥–æ –Ω–µ –¥–µ–ª–∞—Ç—å.
        """)
        
        st.markdown(""" 
        –ú—ã –∑–∞–º–µ–Ω–∏–ª–∏ —Å–∏–º–≤–æ–ª "+" –Ω–∞ 1 –∏ —Å–∏–º–≤–æ–ª "-" –Ω–∞ 0 –≤ —Å—Ç–æ–ª–±—Ü–µ A16.
        """)
        st.subheader("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –º–µ—Ç–∫–∏ –∫–ª–∞—Å—Å–æ–≤")
        st.dataframe(data.head(num_rows))
        st.subheader("üîπ –®–∞–≥ 3: –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        st.markdown(""" 
        ### –°–Ω–∞—á–∞–ª–∞ —É–¥–∞–ª–∏–º —Ä–µ–∞–ª—å–Ω–æ –∫–∞—Ç–µ–≥–æ—Ä–∏–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, —á—Ç–æ–±—ã –±—ã–ª–æ —É–¥–æ–±–Ω–æ:
        –ü–æ–ª—è, –∫–æ—Ç–æ—Ä—ã–µ —É–¥–∞–ª—è—Ç—Å—è: ["A1", "A4", "A5", "A6", "A7", "A9", "A10", "A12", "A13"]
        
        –ü–æ—Å–ª–µ —ç—Ç–æ–≥–æ –∑–∞–º–µ–Ω–∏–º –≤—Å–µ –Ω–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è, —Ç–∞–∫–∏–µ –∫–∞–∫ "?" –Ω–∞ —Å—Ä–µ–¥–Ω–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è.
        """)
        
        processed_data = preprocess_features(data)
        st.subheader("–û–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ")
        st.dataframe(processed_data.head(num_rows))
        buffer = io.StringIO()
        processed_data.info(buf=buffer)
        info_str = buffer.getvalue()
        st.subheader("üî¢ –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –¥–∞–Ω–Ω—ã—Ö –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        st.text(info_str)
        st.subheader("üìâ –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö")
        st.write(processed_data.isna().sum())

        csv = processed_data.to_csv(index=False)
        st.download_button("–°–∫–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ", csv, "processed_data.csv", "text/csv")

        # –®–∞–≥ 4:
        st.subheader("üîπ –®–∞–≥ 4: –û—Ç–±–æ—Ä –ø—Ä–∏–∑–Ω–∞–∫–æ–≤")
        significant_features = feature_selection(processed_data)
        st.subheader("üîπ –¢—Ä–∏ –Ω–∞–∏–±–æ–ª–µ–µ –∑–Ω–∞—á–∏–º—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏:")
        st.write(significant_features)
        st.subheader("üîπ –®–∞–≥ 5: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –¥–∞–Ω–Ω—ã—Ö")
        plot_3d_graph(processed_data)
        st.subheader("üîπ –®–∞–≥ 6: –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è")
        knc, log_reg, dtc, X_train, X_test, y_train, y_test = classification_models(processed_data)
        evaluate_models(knc, log_reg, dtc, X_train, X_test, y_train, y_test)
        st.subheader("üîπ –®–∞–≥ 7: –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü —Ä–µ—à–µ–Ω–∏–π")
        #plot_decision_boundaries(X_train, y_train, knc, log_reg, dtc)
        st.subheader("üîπ –®–∞–≥ 8: ROC-–∫—Ä–∏–≤—ã–µ") 
        plot_roc_curves(knc, log_reg, dtc, X_test, y_test)
        st.subheader("üîπ 9. –û—Ü–µ–Ω–∫–∞ –∫–∞—á–µ—Å—Ç–≤–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏")
        evaluate_models(knc, log_reg, dtc, X_train, X_test, y_train, y_test)
        st.write("–í–∏–¥–Ω–æ —á—Ç–æ —É –º–∞–¥–µ–ª–µ–π KNN –∏ Decission Tree –ø–µ—Ä–µ–æ–±—É—á–µ–Ω–∏–µ —Ç–∞–∫ –∫–∞–∫ —É –Ω–∏—Ö –Ω–∞ —Ç—Ä–µ–π–Ω–µ –≤—ã—Å–æ–∫–∏–π –ø–æ–∫–∞–∑–∞—Ç–µ–ª—å –∞ –Ω–∞ —Ç–µ—Å—Ç–µ –Ω–∏–∑–∫–∏–π. –ê —É –º–æ–¥–µ–ª–∏ Logistic Regression —Ç–∞–∫–æ–≥–æ –Ω–µ—Ç. –ø–æ —ç—Ç–æ–º—É –±—É–¥–µ–º —Å—á–∏—Ç–∞—Ç—å —á—Ç–æ —Å–∞–º—ã–π —Ö–æ—Ä–æ—à—ã–π –º–æ–¥–µ–ª—å —ç—Ç–æ - Logistic Regression")
        st.subheader("üîπ 10. –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ")
        analyze_classification_results(knc, log_reg, dtc, X_test, y_test)
        visualize_data(processed_data)

if __name__ == "__main__":
    main()
